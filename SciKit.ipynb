{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download dataset and split into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not download MNIST data from mldata.org, trying alternative...\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##Prepare the dataset\n",
    "from six.moves import urllib\n",
    "\n",
    "print(\"Could not download MNIST data from mldata.org, trying alternative...\")\n",
    "\n",
    "# Alternative method to load MNIST, if mldata.org is down\n",
    "from scipy.io import loadmat\n",
    "mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "mnist_path = \"./mnist-original.mat\"\n",
    "response = urllib.request.urlopen(mnist_alternative_url)\n",
    "with open(mnist_path, \"wb\") as f:\n",
    "    content = response.read()\n",
    "    f.write(content)\n",
    "mnist_raw = loadmat(mnist_path)\n",
    "mnist = {\n",
    "    \"data\": mnist_raw[\"data\"].T,\n",
    "    \"target\": mnist_raw[\"label\"][0],\n",
    "    \"COL_NAMES\": [\"label\", \"data\"],\n",
    "    \"DESCR\": \"mldata.org dataset: mnist-original\",\n",
    "}\n",
    "print(\"Success!\")\n",
    "\n",
    "X,y = mnist['data'], mnist['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART ONE: MINIST classification using scikit learn\n",
    "###### Set up environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load scikit's support vector machine library\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load numpy\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load scikit's grid search cross validation library\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import accuracy score library\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform a 3-fold grid search and train the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'n_estimators': [3, 10, 30], 'max_features': [100, 300, 784]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set grid search parameters\n",
    "param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [100, 300, 784]}]\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Train rfc model across 3 folds\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv = 3)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review best model\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9654\n"
     ]
    }
   ],
   "source": [
    "# Test final model and calculate accuracy\n",
    "final_model = grid_search.best_estimator_\n",
    "y_pred = final_model.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform a 3-fold grid search and train the Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jding/anaconda3/envs/myenv/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/jding/anaconda3/envs/myenv/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/jding/anaconda3/envs/myenv/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "std_X_train = scaler.transform(X_train)\n",
    "std_X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'kernel': ['linear'], 'C': [10.0, 30.0, 100.0], 'probability': [False]}, {'kernel': ['poly'], 'C': [1.0, 3.0, 5.0], 'gamma': [0.01, 0.03, 0.08], 'probability': [False]}, {'kernel': ['rbf'], 'C': [2.8], 'gamma': [0.0073], 'probability': [False]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set grid parameters\n",
    "param_grid2 = [\n",
    "        {'kernel': ['linear'], 'C': [10., 30., 100.],'probability':[False]},\n",
    "        {'kernel': ['poly'], 'C': [1.0, 3.0, 5.0],'gamma': [0.01, 0.03, 0.08],'probability':[False]},\n",
    "        {'kernel': ['rbf'],'C': [2.8],'gamma': [0.0073],'probability': [False]}\n",
    "]\n",
    "svm = SVC()\n",
    "\n",
    "# Train svc model across 3 folds using the first 10000 datapoints\n",
    "grid_search = GridSearchCV(svm, param_grid2, cv = 3)\n",
    "grid_search.fit(std_X_train[:10000], y_train[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the best estimators from grid search\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train selected model with the remaining 50000 data points.\n",
    "svm_trained = SVC(C=1.0, gamma = 0.01, kernel='poly', probability=False)\n",
    "svm_trained.fit(std_X_train[10000:], y_train[10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8811\n"
     ]
    }
   ],
   "source": [
    "# Test trained model and calculate accuracy\n",
    "#y_pred2 = svm_trained.predict(X_test)\n",
    "print(\"Accuracy: \", svm_trained.score(std_X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
